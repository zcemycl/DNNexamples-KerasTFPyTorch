{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e659db6090>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 1000\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(3):\n",
    "  plt.subplot(1,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,64,2,1,1)\n",
    "        self.conv1_drop = nn.Dropout2d()\n",
    "        self.conv2 = nn.Conv2d(64,32,2,1,1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(7*7*32, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_drop(F.max_pool2d(F.relu(self.conv1(x)),2))\n",
    "        x = self.conv2_drop(F.max_pool2d(F.relu(self.conv2(x)),2))\n",
    "        x = x.view(-1, 7*7*32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\44754\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3090, Accuracy: 987/10000 (10%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307070\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-ef6e122ea50c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-4ae8100a0a83>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = network(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
