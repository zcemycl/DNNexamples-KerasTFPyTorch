{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in the our text: ['my', 'cat', 'is', 'a', 'great', 'cat']\n"
     ]
    }
   ],
   "source": [
    "text = 'My cat is a great cat'\n",
    "tokens = text.lower().split()\n",
    "print('Words in the our text:', tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "great    0\n",
       "my       1\n",
       "a        2\n",
       "is       3\n",
       "cat      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(tokens)\n",
    "vocab = pd.Series(range(len(vocab)), index=vocab)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>cat</th>\n",
       "      <th>great</th>\n",
       "      <th>is</th>\n",
       "      <th>my</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  cat  great  is  my\n",
       "0  0    0      0   0   1\n",
       "1  0    1      0   0   0\n",
       "2  0    0      0   1   0\n",
       "3  1    0      0   0   0\n",
       "4  0    0      1   0   0\n",
       "5  0    1      0   0   0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 3, 2, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = vocab.loc[tokens].values\n",
    "word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# TensorFlow has an operation for one-hot encoding\n",
    "one_hot_inputs = tf.one_hot(inputs, len(vocab))\n",
    "\n",
    "transformed = tf.Session().run(one_hot_inputs, {inputs: word_ids})\n",
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2797505   0.566662   -1.2156818 ]\n",
      " [-0.73898786 -1.5640157  -1.5561099 ]\n",
      " [-0.8949445   0.43797335  1.4428164 ]\n",
      " [-0.5304903  -1.8031386  -0.25690705]\n",
      " [-0.31393436  0.8919702  -1.0153612 ]\n",
      " [-0.73898786 -1.5640157  -1.5561099 ]]\n",
      "[[-0.31393436  0.8919702  -1.0153612 ]\n",
      " [-0.2797505   0.566662   -1.2156818 ]\n",
      " [-0.5304903  -1.8031386  -0.25690705]\n",
      " [-0.8949445   0.43797335  1.4428164 ]\n",
      " [-0.73898786 -1.5640157  -1.5561099 ]]\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 3\n",
    "\n",
    "inputs = tf.placeholder(tf.int32, [None], name='word_ids')\n",
    "\n",
    "# This is where the embedding vectors live\n",
    "# This will be modified by the optimization unless trainable=False\n",
    "# I choose random normal distribution but you can try other distributions\n",
    "embeddings = tf.random_normal(shape=(len(vocab), embedding_size))\n",
    "\n",
    "# this will return the embedding lookup\n",
    "embedded = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "[original,transformed] = sess.run([embeddings,embedded],{inputs: word_ids})\n",
    "print(transformed)\n",
    "print(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 35], [42, 7], [43, 10], [5, 7], [26], [31], [28, 10], [38, 42], [28, 7], [29, 24, 35, 14]]\n",
      "[[ 4 35  0  0]\n",
      " [42  7  0  0]\n",
      " [43 10  0  0]\n",
      " [ 5  7  0  0]\n",
      " [26  0  0  0]\n",
      " [31  0  0  0]\n",
      " [28 10  0  0]\n",
      " [38 42  0  0]\n",
      " [28  7  0  0]\n",
      " [29 24 35 14]]\n",
      "WARNING:tensorflow:From C:\\Users\\44754\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\44754\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\44754\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!','Good work','Great effort',\n",
    "        'nice work','Excellent!','Weak',\n",
    "        'Poor effort!','not good','poor work','Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example for TF\n",
    "Param for embedding = 400 (50 vocabs * 8 embedding size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.reshape((-1,1))\n",
    "\n",
    "FCW1 = weight_variable([32,1])\n",
    "FCb1 = bias_variable([1])\n",
    "\n",
    "targets = tf.placeholder(tf.float32,[None,1], name='labels')\n",
    "inputs = tf.placeholder(tf.int32,[None,4], name='word_ids')\n",
    "embeddings = tf.random_normal(shape=(50,8))\n",
    "embedded = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "z = tf.reshape(embedded,[-1,4*8])\n",
    "z = tf.matmul(z,FCW1) + FCb1\n",
    "# define the loss function\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets,logits=z)\n",
    "correct_prediction = tf.equal(tf.argmax(z, 1), tf.argmax(targets, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# define training step and accuracy\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 1\n",
      "step 1, training accuracy 1\n",
      "step 2, training accuracy 1\n",
      "step 3, training accuracy 1\n",
      "step 4, training accuracy 1\n",
      "step 5, training accuracy 1\n",
      "step 6, training accuracy 1\n",
      "step 7, training accuracy 1\n",
      "step 8, training accuracy 1\n",
      "step 9, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(10):\n",
    "        train_accuracy = sess.run(accuracy,feed_dict={\n",
    "                inputs:padded_docs,targets:labels})\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        sess.run(train_step, feed_dict={inputs:padded_docs,\n",
    "                                        targets:labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
